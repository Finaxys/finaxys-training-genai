{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5bcee9-6588-4d29-bbb9-6fb351ef6630",
   "metadata": {},
   "source": [
    "# L1 Language Models, the Chat Format and Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797991-8486-4d79-8c1d-5dc0c1289c2f",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "#### Chargement de la cl√© API et des librairies n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cd4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed96988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73207e48-02a1-4e7e-bf41-ba29ee11ecfc",
   "metadata": {},
   "source": [
    "**Note**: Tous les notebooks suivants utilisent la version `0.27.0` de la biblioth√®que d'OpenAI. \n",
    "\n",
    "Pour utiliser la version `1.0.0`, il faut utiliser la version suivante : \n",
    "\n",
    "```python\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10a390-2461-447d-bf8b-8498db404c44",
   "metadata": {},
   "source": [
    "## Interroger le mod√®le et obtenir la r√©ponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1cc57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"Quelle est la capitale de la France ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76774108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capitale de la France est Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d4e38-3e3c-4c5a-a949-040a27f29d63",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2d9e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En inversant les lettres de 'lollipop', on obtient 'popillol'.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Prenez les lettres de 'lollipop' et inversez-les.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b14d0-749d-4a79-9812-7b00ace9ae6f",
   "metadata": {},
   "source": [
    "\"lollipop\" in reverse should be \"popillol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37cab84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"\"\"Prenez les lettres de\n",
    "l-o-l-l-i-p-o-p et inversez-les.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1577c561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En inversant les lettres de \"l-o-l-l-i-p-o-p\", on obtient \"p-o-p-i-l-l-o-l\".'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b88940-d3ab-4c00-b5c0-31531deaacbd",
   "metadata": {},
   "source": [
    "## Fonction helper (chat format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f89efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-4o-mini\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b28c3424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il √©tait une fois, dans un jardin enchant√©, une carotte joyeuse nomm√©e Carla. Carla avait une belle robe orange, brillante sous les doux rayons du soleil, et un feuillage vert √©meraude qui dansait au gr√© du vent. Chaque matin, elle se r√©veillait en voyant les autres l√©gumes autour d'elle, tous v√™tus de leurs plus belles couleurs. Mais Carla, elle, avait une particularit√© : elle chantait d√®s le lever du soleil !\n",
      "\n",
      "¬´ La la la, je suis une carotte en or ! ¬ª chantait-elle gaiement, ce qui attirait les abeilles, les papillons et m√™me les oiseaux qui venaient √©couter ses m√©lodies.\n",
      "\n",
      "Tous les jours, Carla r√™vait de voyages au-del√† du potager. Elle avait entendu les histoires racont√©es par un vieux radis sage qui parlait d'une ville o√π les l√©gumes parsemaient les rues et o√π les gens les adoraient. \"Oh, comme j'aimerais y aller !\" se disait-elle en sautillant joyeusement.\n",
      "\n",
      "Un jour, alors qu'elle profitait du doux parfum des fleurs, elle rencontra un petit lapin nomm√© L√©on. Elle lui confia son r√™ve d‚Äôaventure. ¬´ Pourquoi ne viendrais-tu pas avec moi, Carla ? ¬ª lui proposa L√©on en battant des pattes avec enthousiasme. ¬´ Je connais un chemin secret √† travers la for√™t qui nous m√®nera jusqu‚Äô√† cette ville ! ¬ª\n",
      "\n",
      "Enthousiasm√©e, Carla accepta avec joie. Le lendemain, avant m√™me que le soleil ne pointe son nez, L√©on et Carla s‚Äôen all√®rent, la carotte dansant au rythme de ses chants heureux. Ils travers√®rent des rivi√®res scintillantes, saut√®rent par-dessus des pierres moussues et rencontr√®rent des amis incroyables en chemin, comme une tortue sage qui leur racontait des histoires de la for√™t.\n",
      "\n",
      "Apr√®s une longue marche, ils atteignirent enfin la ville des l√©gumes. Oh, quelle vue magnifique ! Les rues √©taient d√©cor√©es de lanternes brillantes et les l√©gumes se promenaient avec fiert√©. Carla, √©merveill√©e, se mit √† chanter encore plus fort :\n",
      "\n",
      "¬´ La la la, venez voir ma belle couleur ! ¬ª\n",
      "\n",
      "Les habitants, s√©duits par sa jolie voix, s‚Äôarr√™t√®rent pour l'√©couter. Tr√®s vite, elle fut entour√©e d‚Äôune foule joyeuse qui dansait et chantait avec elle. Carla √©tait\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"Vous √™tes un assistant qui r√©ponds en prenant le style d'un conteur pour enfants.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"Ecrivez une histoire sur une carotte heureuse.\"\"\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56c6978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans un jardin ensoleill√©, une carotte nomm√©e Carotina grandissait joyeusement, r√™vant de devenir la star des salades.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'Toutes vos r√©ponses doivent √™tre d\"une seule phrase.'},    \n",
    "{'role':'user',\n",
    " 'content':'Ecrivez une histoire sur une carotte heureuse.'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14fd6331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il √©tait une fois, dans un jardin ensoleill√©, une carotte joyeuse qui r√™vait de raconter ses aventures aux autres l√©gumes en dansant sous la douce brise du matin.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"\"\"Vous √™tes un assistant qui r√©ponds en prenant le style d'un conteur pour enfants.\n",
    "Toutes vos r√©ponses doivent √™tre d\"une seule phrase.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"Ecrivez une histoire sur une carotte heureuse.\"\"\"},\n",
    "] \n",
    "response = get_completion_from_messages(messages, \n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a70c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-4o-mini\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    \n",
    "    token_dict = {\n",
    "'prompt_tokens':response.usage.prompt_tokens,\n",
    "'completion_tokens':response.usage.completion_tokens,\n",
    "'total_tokens':response.usage.total_tokens,\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64cf3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"Vous √™tes un assistant qui r√©ponds en prenant le style d'un conteur pour enfants.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"Ecrivez une tr√®s court po√®me sur une carotte heureuse.\"\"\"},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd8fbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans le jardin, sous le soleil dor√©,  \n",
      "Une carotte dansait, toute √©merveill√©e.  \n",
      "Ses feuilles vertes, comme des bras,  \n",
      "Lui murmuraient : \"Regarde, c'est la joie, l√†-bas !\"  \n",
      "\n",
      "Elle r√™vait de g√¢teaux, de soupes bien chaudes,  \n",
      "D'un monde o√π les l√©gumes sont tous en ode.  \n",
      "Avec un sourire, elle poussait bien droit,  \n",
      "Car la carotte heureuse, c'est un vrai petit roi ! üå±ü•ï‚ú®\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "352ad320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 43, 'completion_tokens': 109, 'total_tokens': 152}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65372cdd-d869-4768-947a-0173e7f96335",
   "metadata": {},
   "source": [
    "#### Notes sur l'utilisation de l'API OpenAI en dehors de cette salle de classe.\n",
    "\n",
    "Pour installer la biblioth√®que Python OpenAI :\n",
    "```\n",
    "!pip install openai\n",
    "```\n",
    "\n",
    "La biblioth√®que doit √™tre configur√©e avec la cl√© secr√®te de votre compte, qui est disponible sur le [site web](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "Vous pouvez soit la d√©finir comme variable d'environnement `OPENAI_API_KEY` avant d'utiliser la biblioth√®que :\n",
    " ```\n",
    " !export OPENAI_API_KEY='sk-...'\n",
    " ```\n",
    "\n",
    "Ou, d√©finir `openai.api_key` :\n",
    "\n",
    "```\n",
    "import openai\n",
    "openai.api_key = \"sk-...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f889c1-f2e4-40a5-bd27-164facb54402",
   "metadata": {},
   "source": [
    "#### Remarque compl√©mentaire\n",
    "- Dans ce cours nous utiliserons les antislashs `\\` pour que le texte rentre dans l'√©cran sans utiliser une nouvelle ligne '\\n'.\n",
    "- GPT-4 n'est pas vraiment affect√© par l'insertion de caract√®res de nouvelle ligne ou non. Mais en travaillant avec des LLM en g√©n√©ral, vous pouvez consid√©rer si les caract√®res de nouvelle ligne dans votre prompt peuvent affecter les performances du mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dcc54-f941-422e-8602-d8e78a0da093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
