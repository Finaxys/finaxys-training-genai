{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73e7a07-98a4-4927-9afe-aaab97592564",
   "metadata": {},
   "source": [
    "# L9: Evaluation Part II\n",
    "\n",
    "Évaluer les réponses des LLM lorsque qu'il n'y a pas de « bonne réponse » unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc3130-511d-4830-8066-e73c9261c452",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "#### Chargement de la clé OpenAI et des librairies Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import utils\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-4o-mini\", temperature=0, max_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc82619-ecfe-4b5e-b8d4-1db03db11fc1",
   "metadata": {},
   "source": [
    "### Parcourir le système de bout en bout pour répondre à la demande de l'utilisateur\n",
    "\n",
    "Ces fonctions d'aide exécutent la chaîne de prompts que vous avez vue dans les vidéos précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eae3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg = f\"\"\"\n",
    "Parlez-moi du SmartX ProPhone et de l'appareil photo FotoSnap, le reflex numérique.\n",
    "Quelles télévisions ou produits liés à la télévision avez-vous également ?\"\"\"\n",
    "\n",
    "products_by_category = utils.get_products_from_query(customer_msg)\n",
    "products_by_category = '\\n'.join([line for line in products_by_category.split('\\n') if not line.strip().startswith('```')])\n",
    "category_and_product_list = utils.read_string_to_list(products_by_category)\n",
    "product_info = utils.get_mentioned_product_info(category_and_product_list)\n",
    "assistant_answer = utils.answer_user_msg(user_msg=customer_msg,\n",
    "                                                   product_info=product_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assistant_answer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1411a11-c7e3-4124-983d-149eeb2a34b1",
   "metadata": {},
   "source": [
    "### Évaluer la réponse du LLM à l'utilisateur selon un barème, basé sur les informations sur les produits extraites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prod_info = {\n",
    "    'customer_msg': customer_msg,\n",
    "    'context': product_info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395cbf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_rubric(test_set, assistant_answer):\n",
    "\n",
    "    cust_msg = test_set['customer_msg']\n",
    "    context = test_set['context']\n",
    "    completion = assistant_answer\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    Vous êtes un assistant qui évalue la qualité des réponses du service client à \n",
    "    une question de l'utilisateur en examinant le contexte que l'agent du service \n",
    "    client utilise pour générer sa réponse. \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "    Vous évaluez une réponse soumise à une question en fonction du contexte que l'agent \n",
    "    utilise pour répondre à la question. Voici les données :\n",
    "    [DÉBUT DES DONNÉES]\n",
    "    ************\n",
    "    [Question] : {cust_msg}\n",
    "    ************\n",
    "    [Contexte] : {context}\n",
    "    ************\n",
    "    [Soumission] : {completion}\n",
    "    ************\n",
    "    [FIN DES DONNÉES]\n",
    "\n",
    "    Comparez le contenu factuel de la réponse soumise avec le contexte.\n",
    "    Ignorez toute différence de style, de grammaire ou de ponctuation.\n",
    "    Répondez aux questions suivantes :\n",
    "\n",
    "    La réponse de l'assistant est-elle basée uniquement sur le contexte fourni ? (O ou N)\n",
    "    La réponse inclut-elle des informations qui ne sont pas fournies \n",
    "    dans le contexte ? (O ou N)\n",
    "    Y a-t-il un désaccord entre la réponse et le contexte ? (O ou N)\n",
    "    Comptez combien de questions l'utilisateur a posées. (output un nombre)\n",
    "    Pour chaque question posée par l'utilisateur, y a-t-il une réponse correspondante ?\n",
    "    Question 1 : (O ou N)\n",
    "    Question 2 : (O ou N)\n",
    "    ...\n",
    "    Question N : (O ou N)\n",
    "    Parmi le nombre de questions posées, combien d'entre elles ont été \n",
    "    abordées par la réponse ? (output un nombre) \n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "\n",
    "    response = get_completion_from_messages(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_output = eval_with_rubric(cust_prod_info, assistant_answer)\n",
    "print(evaluation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836eb97c-025b-4643-823f-7fd3fac6ce20",
   "metadata": {},
   "source": [
    "### Évaluez la réponse de l'LLM à l'utilisateur en fonction d'une réponse \"idéale\" / \"expert\" (générée par un humain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_ideal = {\n",
    "    'customer_msg': \"\"\"\n",
    "Parle-moi du SmartX Pro Phone et de la caméra FotoSnap, celle qui est DSLR.\n",
    "Aussi, quels téléviseurs ou produits liés aux téléviseurs avez-vous ?\"\"\",\n",
    "    'ideal_answer':\"\"\"\n",
    "Bien sûr ! Le SmartX ProPhone est un smartphone puissant avec des fonctionnalités \n",
    "avancées pour la caméra. Par exemple, il possède un double appareil photo de 12 MP.\n",
    "D'autres caractéristiques incluent la connectivité 5G et 128 Go de stockage.\n",
    "Il a également un écran de 6,1 pouces. Le prix est de 899,99 $.\n",
    "\n",
    "La caméra reflex numérique FotoSnap est idéale pour capturer des photos et des vidéos \n",
    "époustouflantes. Parmi ses fonctionnalités, on trouve la vidéo en 1080p, un écran LCD \n",
    "de 3 pouces, un capteur de 24,2 MP et des objectifs interchangeables.\n",
    "Le prix est de 599,99 $.\n",
    "\n",
    "Pour les téléviseurs et les produits connexes, nous proposons 3 téléviseurs.\n",
    "\n",
    "Tous les téléviseurs offrent la HDR et les fonctionnalités Smart TV.\n",
    "\n",
    "Le téléviseur CineView 4K présente des couleurs vives et des fonctionnalités intelligentes.\n",
    "Parmi ces fonctionnalités, on trouve un écran de 55 pouces et une résolution 4K.\n",
    "Il est au prix de 599 $.\n",
    "\n",
    "Le téléviseur CineView 8K est un téléviseur 8K époustouflant.\n",
    "Parmi ses fonctionnalités, on trouve un écran de 65 pouces et une résolution 8K.\n",
    "Il est au prix de 2999,99 $.\n",
    "\n",
    "Le téléviseur CineView OLED vous permet de vivre des couleurs vives.\n",
    "Parmi ses fonctionnalités, on trouve un écran de 55 pouces et une résolution 4K.\n",
    "Il est au prix de 1499,99 $.\n",
    "\n",
    "Nous proposons également 2 produits de home cinéma, tous deux dotés de Bluetooth.\n",
    "Le home cinéma SoundMax est un système puissant pour une expérience audio immersive.\n",
    "Ses caractéristiques incluent un son surround 5.1, une puissance de 1000W et un\n",
    "caisson de basses sans fil. Il est au prix de 399,99 $.\n",
    "\n",
    "La barre de son SoundMax est une barre de son élégante et puissante.\n",
    "Ses caractéristiques incluent un son surround 2.1, une puissance de 300W et un\n",
    "caisson de basses sans fil. Elle est au prix de 199,99 $.\n",
    "\n",
    "Avez-vous d'autres questions supplémentaires concernant ces produits que vous\n",
    "avez mentionnés ici ? Ou avez-vous d'autres questions auxquelles je peux vous aider ?\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cceac4-0d92-48db-99de-4d6776ba96e8",
   "metadata": {},
   "source": [
    "### Vérifiez si la réponse de l'IA est d'accord ou en désaccord avec la réponse de l'expert.\n",
    "\n",
    "Le prompt provient du projet [OpenAI evals](https://github.com/openai/evals/blob/main/evals/registry/modelgraded/fact.yaml).\n",
    "\n",
    "[BLEU score](https://en.wikipedia.org/wiki/BLEU): Une autre façon d'évaluer si deux morceaux de texte sont similaires ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596db8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_vs_ideal(test_set, assistant_answer):\n",
    "\n",
    "    cust_msg = test_set['customer_msg']\n",
    "    ideal = test_set['ideal_answer']\n",
    "    completion = assistant_answer\n",
    "    \n",
    "    system_message = \"\"\"\\\n",
    "    Vous êtes un assistant qui évalue la qualité des réponses d'un agent du \n",
    "    service client à une question d'utilisateur en comparant la réponse à la \n",
    "    réponse idéale (d'expert). Output a single letter and nothing else.\n",
    "    \"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\\\n",
    "    Vous comparez une réponse soumise à une réponse d'expert sur une question donnée. Voici les données :\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {cust_msg}\n",
    "    ************\n",
    "    [Expert]: {ideal}\n",
    "    ************\n",
    "    [Submission]: {completion}\n",
    "    ************\n",
    "    [END DATA]\n",
    "\n",
    "Comparez le contenu factuel de la réponse soumise avec la réponse de l'expert. Ignorez les différences de style, de grammaire ou de ponctuation.\n",
    "La réponse soumise peut être soit un sous-ensemble, soit un sur-ensemble de la réponse de l'expert, ou elle peut être en conflit avec celle-ci. Déterminez quel cas s'applique. Répondez à la question en sélectionnant l'une des options suivantes :\n",
    "(A) La réponse soumise est un sous-ensemble de la réponse de l'expert et est entièrement cohérente avec elle.\n",
    "(B) La réponse soumise est un sur-ensemble de la réponse de l'expert et est entièrement cohérente avec elle.\n",
    "(C) La réponse soumise contient tous les mêmes détails que la réponse de l'expert.\n",
    "(D) Il y a un désaccord entre la réponse soumise et la réponse de l'expert.\n",
    "(E) Les réponses diffèrent, mais ces différences n'ont pas d'importance du point de vue de la factualité.\n",
    "choice_strings : ABCDE\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "\n",
    "    response = get_completion_from_messages(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assistant_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7790cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_vs_ideal(test_set_ideal, assistant_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ff694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_answer_2 = \"La vie est comme une boite de chocolats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_vs_ideal(test_set_ideal, assistant_answer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05200847-7746-4657-8848-600ca6be9ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
