{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c411b44-d350-4e1f-96bf-268bc5b9338d",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e218c97c-8299-4978-ba2e-63c17fa44f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cb0582-601f-4af5-ad1d-dff3664a4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743417c-a28d-4221-bc59-80f5336dd431",
   "metadata": {},
   "source": [
    "## Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ce5142-f13e-4958-865e-797cddef1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd0fb1-1950-4aec-b028-f6b426c5a7b5",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2979cc-ec52-4b3a-bff6-1acc5626eb9b",
   "metadata": {},
   "source": [
    "### Legacy Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cc01bb-2769-4d1b-b525-72bba3a93d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrebittner/miniforge3/envs/finaxys-training-genai/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=model, prompt=prompt, output_parser=output_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a4c76d-367a-43c4-8eda-bde307b2bd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrebittner/miniforge3/envs/finaxys-training-genai/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship anymore!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(topic=\"bears\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159e09f1-a649-4ba9-a21a-9ebb4c5fc697",
   "metadata": {},
   "source": [
    "### LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20dc6267-ef63-4969-98f6-9f9acbd72bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cbc339-9be9-474a-91c5-05f837796b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship anymore!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef091b-5a4c-45db-a05e-f037ae259a32",
   "metadata": {},
   "source": [
    "#### Parallel Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ead7e1-b533-4ced-9505-0d0b10aacdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship any longer!\",\n",
       " 'poem': AIMessage(content='In the forest deep and wild,  \\nThe bear roams free, untamed and wild.', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 15, 'total_tokens': 34}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-87668d2c-f854-443c-8a88-99970c739e64-0')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "# joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "poem_chain = (\n",
    "    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n",
    ")\n",
    "\n",
    "map_chain = RunnableParallel(joke=chain, poem=poem_chain)\n",
    "\n",
    "map_chain.invoke({\"topic\": \"bear\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04dff0-afb1-4859-8ed1-184664f4a44d",
   "metadata": {},
   "source": [
    "## QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2557a0dd-1dbf-4703-a153-571b6e00aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "persist_directory = 'data/chroma/'\n",
    "store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "\n",
    "retriever = store.as_retriever(search_type=\"mmr\", ssearch_kwargs={'k': 10, 'lambda_mult': 0.25})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484f70b9-b706-40a3-8e20-d3563dc58820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded1a1a3-7f57-4709-82b7-c64f88f55917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: filler question \n",
      "Context: filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_prompt.invoke(\n",
    "        {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    "    ).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3ce2c-d215-40a5-b578-be3533f3a439",
   "metadata": {},
   "source": [
    "### Legacy Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8521a6d-4bc3-4177-b1eb-33ede00f2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model, retriever=retriever, verbose=True,\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d1f613-36ad-437c-9f9d-ea1ef61ab4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrebittner/miniforge3/envs/finaxys-training-genai/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The approaches to Task Decomposition include Functional Decomposition, Object-Oriented Decomposition, and Data-Oriented Decomposition. Each approach involves breaking down a task into smaller, more manageable subtasks to simplify the overall process. These approaches help improve efficiency and organization in task completion.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"] # you should get a deprecation warning message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c38e873a-4fa7-4ae1-96fd-53737239b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48398f6f-4aa2-4433-be91-035e9b146fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is the process of breaking down a complex task into smaller, more manageable subtasks. It helps in organizing and prioritizing the steps needed to complete a task efficiently. By dividing a task into smaller components, it becomes easier to assign responsibilities and track progress."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What is Task Decomposition?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3e7a2-1f9d-44b7-9a1c-8e8ef509f4f7",
   "metadata": {},
   "source": [
    "## More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f395dd39-5cb4-47fa-83f3-0e604111c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96faec2f-2292-48c6-a748-41393850d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrebittner/miniforge3/envs/finaxys-training-genai/lib/python3.10/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff33e06-06a3-4a56-a2d6-cf94fcb4c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierrebittner/miniforge3/envs/finaxys-training-genai/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='harrison worked at kensho'),\n",
       " Document(page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38566c31-3089-445b-a886-6c98f6710f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='bears like to eat honey'),\n",
       " Document(page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64632dc5-65bc-4387-bfbe-04fa8c69a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "982165c3-a334-4728-8f3f-985ad1309214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "680e0d87-8be0-414c-8653-981ebfaa0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5ce3547-ba9a-4dac-9cd1-034b52d76e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96ee98f8-00bb-4c32-95e5-be21770ba924",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c30be82-a058-459d-b74f-1f01a8d39694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='harrison worked at kensho'),\n",
       "  Document(page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aacd9a7-810d-4703-bca8-800ec1aaf388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401071eb-f840-47d4-89b8-57c898d73896",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work\", \"language\": \"italian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d8c7b-bdb8-4581-a854-e0af63afcba0",
   "metadata": {},
   "source": [
    "## Bind\n",
    "and OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecf70c-85eb-4339-8304-38975e1c2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3113ae-4b1d-4722-ae4e-d534b6137d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e018671-a7f3-4395-b313-6d9823ec0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3ef98-ef1f-458f-bae5-1579fca078db",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2f320-151d-46b3-946c-d4412ebd28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "        {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ef9bf-6d14-4c96-8bb8-d95f0240d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ce3c2-fe0f-43a4-92c0-b3c7e97ee3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cceec8f-17a9-4ad5-a5c9-89c1a153c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be89ab-e349-4abf-9adf-639d820103cf",
   "metadata": {},
   "source": [
    "## OpenAI Function Calling In LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba1148-ef62-43d9-9cc7-420331c90174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229943f4-d03d-461b-b163-080e31a5d041",
   "metadata": {},
   "source": [
    "### Pydantic Syntax\n",
    "Pydantic data classes are a blend of Python's data classes with the validation power of Pydantic.\n",
    "\n",
    "They offer a concise way to define data structures while ensuring that the data adheres to specified types and constraints.\n",
    "\n",
    "In standard python you would create a class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1edb68-f52c-4036-a291-ba38a9cdf46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, name: str, age: int, email: str):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.email = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ecb656-5d84-49fe-a467-6c83f297a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = User(name=\"Joe\",age=32, email=\"joe@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd122a60-1c50-4516-ab28-815fc391e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6bdbe-bd05-43c0-b6af-347fc0d8b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pUser(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13e300-ef08-46c0-9ed2-c60304b4341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_p = pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297fc86-f83b-4df4-bc93-f3df5f0f5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_p.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0ca01-a96e-4d14-99ad-1bd3d7dd8e4e",
   "metadata": {},
   "source": [
    "### Pydantic to OpenAI function definition¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306869e-959f-4e9e-9b2b-9e83c21919f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherSearch(BaseModel):\n",
    "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
    "    airport_code: str = Field(description=\"airport code to get weather for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21005b0-1f07-419e-b252-b7b1bf33fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e72e65-1818-4e9c-8a39-82fa8b098f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_function = convert_pydantic_to_openai_function(WeatherSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33939304-a47c-4706-8230-8565eb2de61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e32e34-0057-401b-aa65-b38e0e694fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6415f2-1381-4c4b-ba71-498657232d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"what is the weather in SF today?\", functions=[weather_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df9823-d657-4321-9993-e1e05d006bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_function = model.bind(functions=[weather_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a0c6f-f96e-4930-a933-d4264de83c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_function.invoke(\"what is the weather in sf?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1f3fa-9956-4115-acb8-afeea8b9898c",
   "metadata": {},
   "source": [
    "### Using in a chain\n",
    "We can use this model bound to function in a chain as we normally would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34a85b-6976-4377-b2d2-68398446e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692003a6-210f-48f2-bb01-36689cf38d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb6a3a-56b2-4418-8fd1-da642745bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model_with_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39473241-9b4f-4dac-9fe6-7e8a3db849b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde9057-2cf5-4d06-8cf9-c1631476d1c9",
   "metadata": {},
   "source": [
    "### Using multiple functions\n",
    "Even better, we can pass a set of function and let the LLM decide which to use based on the question context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f92f3e-bbb7-4e82-9bbb-9f603cafdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtistSearch(BaseModel):\n",
    "    \"\"\"Call this to get the names of songs by a particular artist\"\"\"\n",
    "    artist_name: str = Field(description=\"name of artist to look up\")\n",
    "    n: int = Field(description=\"number of results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aaeff6-7e4f-49ec-9446-e0a0d565c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    convert_pydantic_to_openai_function(WeatherSearch),\n",
    "    convert_pydantic_to_openai_function(ArtistSearch),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d5402-7c42-442e-9c5f-513330d21aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a6c14-51e4-4384-9e80-bb246a427539",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions.invoke(\"what is the weather in sf?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09084a4c-3794-4ac9-8c0d-f8f5038d5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions.invoke(\"what are three songs by taylor swift?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7bda35-233d-47e1-874d-05f7256dcbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_functions.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de329d74-a9ac-4bc0-91d5-77e88a92d486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
