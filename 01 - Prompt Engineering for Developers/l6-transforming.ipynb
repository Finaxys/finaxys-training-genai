{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3993515-9710-4ac4-89e9-b35ebb81e920",
   "metadata": {
    "id": "rhqRhkElpJ0z"
   },
   "source": [
    "# Transformation\n",
    "\n",
    "Dans ce notebook, nous explorerons comment utiliser les modèles de langage de grande taille pour des tâches de transformation de texte telles que la traduction de langue, la vérification de l'orthographe et de la grammaire, l'ajustement du ton et la conversion de format.\n",
    "\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df0348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85ee0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc",
   "metadata": {
    "id": "zdxC4c6pwqA5"
   },
   "source": [
    "## Traduction\n",
    "\n",
    "ChatGPT est entraîné avec des sources dans de nombreuses langues. Cela donne au modèle la capacité de faire de la traduction. Voici quelques exemples de la manière d'utiliser cette fonctionnalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4df6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduisez le texte anglais suivant en espagnol : \n",
    "```Hi, I would like to order a blender```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300ed9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Dites moi dans quelle langue est écrit le texte suivant : \n",
    "```Combien coûte le lampadaire?```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e789b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduisez le texte suivant en French, en Espagnol et en argot français :\n",
    "```I want to order a basketball```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7eb63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduisez le texte suivant en français à la fois sous les formes formelle et informelle :\n",
    "'Would you like to order a pillow?'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849",
   "metadata": {
    "id": "-hN2bczQrRC1"
   },
   "source": [
    "### Traducteur Universel\n",
    "Imaginez que vous êtes responsable de l'informatique dans une grande entreprise de e-commerce multinationale. Les utilisateurs vous envoient des messages avec des problèmes informatiques dans toutes leurs langues maternelles. Votre équipe vient du monde entier et ne parle que leurs langues natales. Vous avez besoin d'un traducteur universel !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a40bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "  \"System performance is slower than normal.\",                 #La performance du système est plus lente que d'habitude\n",
    "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
    "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
    "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
    "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d0db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for issue in user_messages:\n",
    "    prompt = f\"Dites-moi dans quelle langue est ce texte : ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "    print(f\"Message original : ({lang}): {issue}\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Traduisez le texte suivant en français et en coréen : ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e660eb-324f-474c-acf3-7e3bf5b7c70e",
   "metadata": {},
   "source": [
    "## A vous de jouer !\n",
    "Essayez-vous même quelques traductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57158f-d77d-42d1-94fe-17fa59c012f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5",
   "metadata": {
    "id": "JH3-0vdjsILh"
   },
   "source": [
    "## Modification de style\n",
    "L'écriture peut varier en fonction du public visé. ChatGPT peut produire différents styles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deac328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Traduisez le texte suivant du langage familier à une lettre professionnelle en français : \n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5",
   "metadata": {
    "id": "p3e9sZh5tWIa"
   },
   "source": [
    "## Modification de format\n",
    "ChatGPT peut traduire entre différents formats. L'invite doit décrire les formats d'entrée et de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37f0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_json = { \"resturant employees\" :[ \n",
    "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
    "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
    "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
    "]}\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Traduisez le dictionnaire Python suivant du JSON en une table HTML avec des en-têtes de colonnes et un titre : {data_json}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a46b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe",
   "metadata": {
    "id": "qLTz16qEzyT_"
   },
   "source": [
    "## Vérification de l'orthographe / Vérification grammaticale.\n",
    "\n",
    "Voici quelques exemples de problèmes courants de grammaire et d'orthographe, ainsi que la réponse du LLM.\n",
    "\n",
    "Pour indiquer au LLM que vous souhaitez qu'il relise votre texte, vous demandez au modèle de 'relire' ou de 'relire et corriger'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d77283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = [ \n",
    "  \"La fille avec les chiots noir et blanc ont une balle.\",  # a une balle\n",
    "  \"Yolanda a son carnet\", # ok\n",
    "  \"C'est va être une longue journée. La voiture a-t-elle besoin de son huile changée ?\", \n",
    "  \"Tu vas avoir besoin de tes carnet\", \n",
    "  \"Cette phrase est pour vérifier chatGPT pour l'abilité d'ortohgraphe.\"\n",
    "]\n",
    "for t in text:\n",
    "    prompt = f\"\"\"Relisez et corrigez le texte suivant et réécrivez \n",
    "    la version corrigée. Si vous ne trouvez pas d'erreurs, dites \n",
    "    simplement \"Aucune erreur trouvée\". N'utilisez aucune ponctuation \n",
    "    autour du texte :\n",
    "    ```{t}```\"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543fe7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "J'ai eu ça pour ma fille pour son anniversaire parce qu'elle prend \n",
    "toujours le mien dans ma chambre. Oui, les adultes aime aussi les pandas.\n",
    "Elle l'emporte partout avec elle, et c'est super doux et mignon.\n",
    "Une des oreilles est un peu plus basse que l'autre, et je ne pense \n",
    "pas que ça ait été conçu pour être asymétrique.\n",
    "C'est un peu petit pour ce que j'ai payées.\n",
    "Je pense qu'il pourrait y avoir dautres options qui sont plus grandes pour le même prix.\n",
    "Il est arrivé un jour plus tôt que prévu, donc j'ai pu jouer avec avant de le donner à ma fille.\n",
    "\"\"\"\n",
    "prompt = f\"Analyse et corrige ce commentaire : ```{text}```\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac80a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from redlines import Redlines\n",
    "\n",
    "diff = Redlines(text,response)\n",
    "display(Markdown(diff.output_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e73fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Relis et corrige cette critique. Rends-la plus convaincante.\n",
    "Assure-toi qu'elle respecte le guide de style APA et qu'elle cible un lecteur avancé.\n",
    "Sors le texte au format Markdown.\n",
    "Texte : ```{text}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fb76bc-a742-4b35-9dc2-f7fbc12d38fb",
   "metadata": {},
   "source": [
    "## A vous de jouer\n",
    "Reformule les instructions pour rédiger ta propre critique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2ca58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dbf5020-7d7f-4ba5-840b-20e883cd7c99",
   "metadata": {
    "id": "unsf1JnRr2IC"
   },
   "source": [
    "Merci au site suivant :\n",
    "\n",
    "https://writingprompts.com/bad-grammar-examples/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
